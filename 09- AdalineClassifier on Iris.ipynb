{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad340f5-648a-45da-af6c-b4f8c7294b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391dbe29-7182-4f21-82e3-4a8c3726740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = datasets.load_iris()\n",
    "X_data = data_set.data\n",
    "Y_data = data_set.target\n",
    "\n",
    "sub_data = np.where((Y_data[:,] == 1) | (Y_data[:,] == 2))[0]\n",
    "X = X_data[sub_data]\n",
    "Y = Y_data[sub_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23adf790-4030-40ed-a611-dc6fc56bd5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdelineClassifier:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the AdelineClassifier.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the model to the training data.\n",
    "\n",
    "        Args:\n",
    "        X_train (numpy.ndarray): Input features for training.\n",
    "        y_train (numpy.ndarray): Output labels for training.\n",
    "        \"\"\"\n",
    "        # w = (X.T * X)^-1 * (X.T * Y)\n",
    "        self.w = np.matmul(inv(np.matmul(X_train.T, X_train)), np.matmul(X_train.T, y_train))\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"\n",
    "        Predict the output labels for test data.\n",
    "\n",
    "        Args:\n",
    "        X_test (numpy.ndarray): Input features for testing.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Predicted output labels for the test data.\n",
    "        \"\"\"\n",
    "        y_pred = np.matmul(X_test, self.w)\n",
    "        y_pred = np.round(y_pred, 1)\n",
    "        \n",
    "        return y_pred\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the performance of the model on the test data.\n",
    "\n",
    "        Args:\n",
    "        X_test (numpy.ndarray): Input features for testing.\n",
    "        y_test (numpy.ndarray): True output labels for testing.\n",
    "\n",
    "        Returns:\n",
    "        float: Accuracy of the model on the test data.\n",
    "        \"\"\"\n",
    "        y_pred = np.matmul(X_test, self.w)\n",
    "        y_pred = np.round(y_pred, 1)\n",
    "        \n",
    "        if np.min(y_test) == 0 and np.max(y_test) == 1:\n",
    "            y_pred[y_pred > 0.5] = 1\n",
    "            y_pred[y_pred <= 0.5] = 0\n",
    "            \n",
    "        if np.min(y_test) == 0 and np.max(y_test) == 2:\n",
    "            y_pred[y_pred > 1] = 2\n",
    "            y_pred[y_pred <= 1] = 0\n",
    "\n",
    "        if np.min(y_test) == 1 and np.max(y_test) == 2:\n",
    "            y_pred[y_pred > 1.5] = 2\n",
    "            y_pred[y_pred <= 1.5] = 1\n",
    "            \n",
    "        accuracy = np.count_nonzero(y_pred == y_test) / len(y_test) * 100\n",
    "            \n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3836a9b3-d7d5-4705-99d2-d56ff129035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6465bbb2-b327-4b5f-bb3e-bcf6aa1af505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdelineClassifier()\n",
    "model.fit(X_train, Y_train)\n",
    "print(model.w)\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "print('pred', pred)\n",
    "print('true', Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df288e3d-1f5f-475b-be3b-3b0678f785ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(X_test, Y_test)\n",
    "print('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e374d46e-ccd9-454d-b207-5573ff96e84f",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3843e6d4-7a87-4cd8-b36b-14dc05143738",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbor:\n",
    "    def __init__(self, k):\n",
    "        \"\"\"\n",
    "        Initialize the KNearestNeighbor classifier.\n",
    "\n",
    "        Args:\n",
    "        k (int): Number of nearest neighbors to consider.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit the model to the training data.\n",
    "\n",
    "        Args:\n",
    "        X_train (numpy.ndarray): Input features for training.\n",
    "        y_train (numpy.ndarray): Output labels for training.\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.number_classes = len(np.unique(y_train))\n",
    "    \n",
    "    def nearNeighbors(self, x_test):\n",
    "        \"\"\"\n",
    "        Find the indices of the nearest neighbors for a given test instance.\n",
    "\n",
    "        Args:\n",
    "        x_test (numpy.ndarray): Input features for a single test instance.\n",
    "\n",
    "        Returns:\n",
    "        numpy.ndarray: Indices of the nearest neighbors.\n",
    "        \"\"\"\n",
    "        distance = np.sqrt(np.sum((x_test - self.X_train) ** 2, axis=1))\n",
    "        near_neighbors = np.argsort(distance)[:self.k]\n",
    "        \n",
    "        return near_neighbors\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        \"\"\"\n",
    "        Predict the label for a single test instance.\n",
    "\n",
    "        Args:\n",
    "        x_test (numpy.ndarray): Input features for a single test instance.\n",
    "\n",
    "        Returns:\n",
    "        int: Predicted label for the test instance.\n",
    "        \"\"\"\n",
    "        near_neighbors = self.nearNeighbors(x_test)\n",
    "        predict_label = np.argmax(np.bincount(self.y_train[near_neighbors]))\n",
    "            \n",
    "        return predict_label\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the performance of the model on the test data.\n",
    "\n",
    "        Args:\n",
    "        X_test (numpy.ndarray): Input features for testing.\n",
    "        y_test (numpy.ndarray): True output labels for testing.\n",
    "\n",
    "        Returns:\n",
    "        float: Accuracy of the model on the test data.\n",
    "        \"\"\"\n",
    "        y_pred = []     \n",
    "        \n",
    "        for i in range(len(X_test)):\n",
    "            y_pred.append(self.predict(X_test[i]))\n",
    "            \n",
    "        true_label = np.count_nonzero(y_pred == y_test)\n",
    "        accuracy = (true_label / len(y_pred)) * 100\n",
    "        \n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee9501c-19a4-47c7-8409-4601f5c71a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestNeighbore(5)\n",
    "knn.fit(X_train, Y_train)\n",
    "\n",
    "accuracy = knn.evaluate(X_test, Y_test)\n",
    "\n",
    "print('accuracy', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
